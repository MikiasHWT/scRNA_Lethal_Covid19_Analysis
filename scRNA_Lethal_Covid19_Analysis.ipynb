{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the notebook title\n",
    "Notebook_title = \"scRNA Lethal COVID19 Analysis\"\n",
    "\n",
    "# Get the current date\n",
    "current_date = datetime.now().strftime(\"%B %d, %Y\")\n",
    "\n",
    "# Create the HTML string with title, date, and author\n",
    "html_content = f\"\"\"\n",
    "<h1 style=\"text-align:center;\">{Notebook_title}</h1>\n",
    "<br/>\n",
    "<h3 style=\"text-align:left;\">MikiasHWT</h3>\n",
    "<h3 style=\"text-align:left;\">{current_date}</h3>\n",
    "\"\"\"\n",
    "\n",
    "# Display the HTML content in the output\n",
    "display(HTML(html_content))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "As of November 2024, the [World health Organization](https://data.who.int/dashboards/covid19/cases) reported 777 million (103 million in the US) confirmed cases of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) worldwide, with over 7 million deaths (1.2 million in the US). This coronavirus, commonly known as COVID-19, has had a profound impact on global health, economies, and societies.In this project, I aim to replicate the analyses from the paper [\"A molecular single-cell lung atlas of lethal COVID-19\"](https://www.nature.com/articles/s41586-021-03569-1#data-availability), [DOI: 10.1038/s41586-021-03569-1](https://doi.org/10.1038/s41586-021-03569-1). \n",
    "\n",
    "The original paper provides an in-depth examination of the cellular and molecular alterations in the lungs of individuals who died of COVID-19, utilizing single-nucleus RNA sequencing to analyze lung tissue from 19 patients (12M, 7F, mediage age 72) who died of COVID-19 and biopsy or resection samples from 7 pre-pandemic controls (4M, 3F, median age 70)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "By replicating the various analyses performed by the original authors, I intend to recapitulate the original findings and further explore the pathophysiology of lethal COVID-19. \n",
    "\n",
    "This will include:\n",
    "- Process single-cell RNA sequencing data using sensible quality control metrics.\n",
    "- Cluster and integrate immune cell populations between healthy and COVID-19 samples. \n",
    "- Identify and label immune cell using gene expression profiles and activation states\n",
    "- Characterize differences in cell infilitration, proportions and activation states between healthy and COVID-19 samples. \n",
    "\n",
    "The ultimate goal of this project is to enhance my understanding of the cellular and molecular mechanisms underlying severe COVID-19."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Source\n",
    "The data was made publicly avaible in Gene Expression Omnibus, under [GSE171524](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE171524). \n",
    "I have downloaded the TAR file to a local folder and extracted the CSV files containing the data usuing 7-Zip. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tissue Collection\n",
    "Tissue samples from lethal COVID-19 patients were collected with consent, from New York Presbyterian Hospital or Columbia University Medical Center. Samples were tested for COVID-19 using reverse transcription quantitative polymerace chain reaction (RT-qPCR) and the regions of interest were selected based on pathological review of adjecent Haematoxylin and Eosin (H&E) stained, Formalin-Fixed Parafin-Embedded (FFPE) slides. 1 cm^3 samples were snap frozen in liquid nitrogen, and embedded in Optimal Cutting Temperature (OCT) compound in -80C freezers until processing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tissue Processing\n",
    "In preperation for single-nucleus RNA sequencing tissues were: \n",
    "- Rinced of OCT in ice-cold Phosphate Buffered Saline (PBS).\n",
    "- Mechanically dissociated with fine scissors and pipettes in a buffer containing Tween surfactant (and RNase Inhibitor) to aid in dissociation of cells and extraction of nuclei. \n",
    "- Washed in Tris salt containing buffer and filetered with 70um cell strainers followed by pelleting at 500g and resuspension in an appropriate amount of Tris buffered solution. \n",
    "- Cells were counted by secondary investigator uninvoled with tissue processing before 15,000-20,000 nuclei were loaded per channel on a Chromium controller using Chromium Next GEM Single Cell 3สน v3.1 reagents. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Preparation & Sequencing \n",
    "\n",
    "Chromium Next GEM Single Cell 3สน v3.1 reagents were used to prepare single-nucleus RNA-seq libraries, mostly according to manufacturers recomendation. One additional cDNA amplificiation cycle was included to account for lower RNA yields from nuclei as compared to whole-cell RNA extractions. RNA libraries and cDNA were quantified using D1000 TapeStation and Qubit HS DNA quantification kit. Finally the libraries were pooled in an equimolar mixture and sequenced on a NovaSeq 6000 with S4 flow cell, usuing paired-end, single-index sequencing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "- Raw 3' scRNA-seq data was demultiplexed using Cell Ranger (v5.0).\n",
    "- Trancripts were alligned using a COVID-19 appended human reference genome (GRCh38).\n",
    "- Ambient RNA was removed using CellBender (v.0.2.0). \n",
    "- Expression matrices were procused using Seurat (v.3.2.3). \n",
    "- The following filters were applied to keep nuclei with:\n",
    "    - 200-7500 genes. \n",
    "    - 400-40,000 Unique Molecular Idenitifier(UMI's).\n",
    "    - <10% Mitochondrial reads. \n",
    "- Scrublet was applied with a predicted rate of 4-9.6% to remove nuclei doublets.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep Workplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # Numerical computing library\n",
    "import pandas as pd  # Data manipulation and analysis\n",
    "import matplotlib.pyplot as plt  # Plotting and visualization\n",
    "import seaborn as sns  # Statistical data visualization\n",
    "import scanpy as sc  # Single-cell data analysis\n",
    "import scvi  # Single-cell variational inference for modeling\n",
    "from scipy.stats import median_abs_deviation  # Robust statistic for dispersion\n",
    "import os  # Operating system interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories \n",
    "datDir = os.path.abspath(\"data\")\n",
    "outDir = os.path.abspath(\"output\")\n",
    "\n",
    "# List their contents. \n",
    "for path in [datDir, outDir]:\n",
    "    # os.makedirs(path, exist_ok=True)   # Optional: Create directories if they dont exist\n",
    "    print(f\"Contents of {path}:\")\n",
    "    print(\"\\n\".join(os.listdir(path)) or \"Directory is empty\", \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original authors utilized R programming and Seurat package to analyze and prepare their data. This requires some consideration as we import data processed in R into an Python envirnment, as Seurat sets genes as the rows and cells as the columns while Scanpy reverses this orientation. This can be resolved by transposing the CSV files as we import them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv files into Anndata object\n",
    "adata = sc.read_csv(\"data\\GSE171524_RAW\\GSM5226595_L16cov_raw_counts.csv.gz\").T\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"This sample has {adata.X.shape[0]} cells and {adata.X.shape[1]} transcripts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View cell barcodes\n",
    "adata.obs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View transcripts (genes)\n",
    "adata.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View count matrix\n",
    "adata.X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality Control\n",
    "Unlike Bulk RNA sequencing, single cell RNA sequencing results in far fewer data points, leading to an excessive number of zero's in the count matrix. In addition, the requirement to isolate each cell or nuclei into its own sequencing bead can be difficult to acomplish especially for stromal tissues like epithelial cell and adherent immune cells such as myeloid cells. Not to mention that many cell types such as Neutrophils are infamous for low RNA quanitity and high sensitivity to processing steps. \n",
    "\n",
    "In essence, before we receive data in a count matrix, many considerations must be given to prevent biases in processing. Once the cells have been sequenced, additional consideration must be given to ensure that the appropriate quality control metrics are applied according to processing steps, cells and tissues of interest as well as the scientific question at hand. \n",
    "\n",
    "The original authors performed various quality control methods to filter out low quality reads and doublets. For the sake of posterity, I will inspect the quality of these sample and set additional QC metrics where neccesary. \n",
    "\n",
    "The standard approach for quality control of scRNA data requies that we inspect the following metrics. \n",
    "- The number of counts per barcode (count depth)\n",
    "- The number of genes per barcode\n",
    "- The fraction of counts from mitochondrial genes per barcode\n",
    "\n",
    "It is generally recomended to be permissive while filtering cells as to avoid eliminating viable populations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "By exploring the data and applying QC metrics I aim to:\n",
    "\n",
    "- Remove reads from nuclei extracted from dead or dying cells. \n",
    "- Remove reads from empty droplets. \n",
    "- Remove reads from droplets with more than one nuclei. \n",
    "- Remove reads containing contaminating/ambient RNA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following this section we will have the following metrics for quality control. \n",
    "\n",
    "**Gene Metrics:** \n",
    "- `n_cells_by_counts`: The number of cells in which a given gene (feature) is expressed.\n",
    "    - Identifies whether a gene is highly or lowly expressed.\n",
    "\n",
    "- `mean_counts`: The mean expression of a gene across all cells.\n",
    "\n",
    "- `log1p_mean_counts`: The pseudo logarithm (1+count) of mean_counts.\n",
    "    - Used for visualization or comparison when data ranges are large.\n",
    "\n",
    "- `pct_dropout_by_counts`: The percentage of cells in which a given gene has zero expression.\n",
    "    - Identifies genes that are rarely expressed and may not be informative.\n",
    "\n",
    "**Cell Metrics:** \n",
    "- `n_genes_by_counts`: The number of genes with non-zero expression in each cell.\n",
    "    - Indicates the diversity of gene expression in a cell and is commonly used to filter low-quality cells.\n",
    "    \n",
    "- `total_counts`: The total number of counts (sum of all gene expressions) for each cell.\n",
    "    - Reflects library size or sequencing depth and is used to identify cells with abnormal counts.\n",
    "\n",
    "- `pct_counts_in_top_20_genes`: The percentage of total counts contributed by the top 20 most highly expressed genes.\n",
    "    - Identifies cells dominated by a small number of genes, which can indicate low quality or cell-specific biological properties.\n",
    "\n",
    "**Mitochondrial Gene Metrics:**\n",
    "- `total_counts_mt`: The total counts from mitochondrial genes for each cell.\n",
    "    - Indicates the mitochondrial content in a cell, often used as a proxy for cell health.\n",
    "\n",
    "- `pct_counts_mt`: The percentage of total counts from mitochondrial genes.\n",
    "\n",
    "**Ribosomal Gene Metrics:**\n",
    "- `total_counts_ribo`: The total counts from ribosomal genes for each cell.\n",
    "    - Indicates ribosomal RNA expression, which may identify cells in various stages of replication.\n",
    "    - Depending on question at hand, it may be beneficial to threshold using this metric. \n",
    "\n",
    "- `pct_counts_ribo`: The percentage of total counts from ribosomal genes.\n",
    "\n",
    "**Hemoglobin Gene Metrics:**\n",
    "- `total_counts_hb`: The total counts from hemoglobin genes for each cell.\n",
    "    - High expression could indicate improper red cell removal during processing.\n",
    "    - Depending on the question at hand, it may be useful to remove red cell contamination. Alternively, red blood cells can be used to verify if clustering is being performed correctly.  \n",
    "\n",
    "- `pct_counts_hb`: The percentage of total counts from hemoglobin genes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create QC Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables to idenitify known gene subsets\n",
    "# mitochondrial genes (\"MT-\"\" for human, \"mt-\" for mouse)\n",
    "adata.var[\"mt\"] = adata.var_names.str.startswith(\"MT-\")\n",
    "# ribosomal genes\n",
    "adata.var[\"ribo\"] = adata.var_names.str.startswith((\"RPS\", \"RPL\"))\n",
    "# hemoglobin genes.\n",
    "adata.var[\"hb\"] = adata.var_names.str.contains((\"^HB[^(P)]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate QC metrics using scanpy function\n",
    "sc.pp.calculate_qc_metrics(\n",
    "    adata, \n",
    "    qc_vars=[\"mt\", \"ribo\", \"hb\"], \n",
    "    inplace=True, \n",
    "    percent_top=[20], # finds cumulative precentage of total counts produced by top 20 expressed genes\n",
    "    log1p=True\n",
    ")\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View newly added transcript variables\n",
    "adata.var.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View statistical distribution of qc metrics\n",
    "adata.var.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View newly added cell variables\n",
    "adata.obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View statistical distribution of qc metrics\n",
    "adata.obs.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the describe functions we can get a high level overview of the QC metrics. \n",
    "We note that the QC metrics applied by authors in the preprossing steps are present by inspecting the max and min value of `total_counts`, `n_genes_by_counts` and `pct_count_mt`. \n",
    "\n",
    "We will visualize a subset of the newly defined QC metrics in case there is anything else of note. Specifically we will inspect the plots for any obvious signs of outliers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize QC Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total count = total transcripts (UMI's) per cell (defined in preprossesing to be between 400-40,000)\n",
    "# n_genes_by_counts = number of unique genes per cell (defined in preprosession to be between 200-7500)\n",
    "# pct_counts_mt = percent of mitochondrial genes per cell\n",
    "sc.pl.violin(\n",
    "    adata,\n",
    "    keys=[\"total_counts\", \"n_genes_by_counts\",\"pct_counts_mt\"],\n",
    "    groupby=None,\n",
    "    multi_panel=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot total transcripts by unique genes & color by percent mitrochondrial genes per cell\n",
    "sc.pl.scatter(adata, \"total_counts\", \"n_genes_by_counts\", color=\"pct_counts_mt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply QC Metrics\n",
    "\n",
    "Quality control of data is often an itterative process that consumes a vast majority of an analysis lifecycle. It requires careful considerations of the known, the unknown and the unknown-unknown. In essence, we can never truly claim to have \"finished\" cleaning data, especially in Biology where the data's inherent noise is nearly impossible to seperate from technical noise produced by our method of data collection. \n",
    "\n",
    "In this particular case, the data does not appear overly problematic upon initial inspection. Yet for the sake of exploration we will consider a thresholding methodology to detect outliers using the median values of our QC metrics (keeping in mind that a second round of QC may result in the elimination of valid populations of interest). Using [Germain et al., 2020](https://doi.org/10.1186/s13059-020-02136-7) as reference, we will define an outlier as any data point that lies beyond k Median Absolute Deviations (MAD) from the median. The MAD is a robust measure of variability, calculated as the median of the absolute deviations from the dataset's median. Using the `median_abs_deviation` function from `scipy.stats`, we will compute the MAD and establish thresholds to identify outliers. For this implementation, we will use k=5k=5 as the multiplier.\n",
    "\n",
    "\n",
    "Median Absolute Deviation is defined as:\n",
    "$$\n",
    "\\text{MAD} = \\text{median} \\left( \\lvert X_i - \\text{median}(X) \\rvert \\right)\n",
    "$$\n",
    "\n",
    "\n",
    "Where\n",
    "$\n",
    "X_i\n",
    "$\n",
    "is the respective QC metric for a given cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MAD function\n",
    "def is_outlier(adata, qcmetric: str, madunits: int):\n",
    "    \"\"\"\n",
    "    Identified outlier points using the Mean Absolute Deviation function from scipy\n",
    "\n",
    "    Args:\n",
    "        adata (_type_): Anndata object with RNA data\n",
    "        qcmetric (str): QC metric to use for outlier detection\n",
    "        madunits (int): Value of MAD units to use for the QC metric\n",
    "\n",
    "    Returns:\n",
    "        _type_: Boolean value identifying outliers\n",
    "    \"\"\"\n",
    "    M = adata.obs[qcmetric]\n",
    "    outlier = (M < np.median(M) - madunits * median_abs_deviation(M)) | (M > np.median(M) + madunits * median_abs_deviation(M))\n",
    "    return outlier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to select our QC metrics for outlier detection, i would like to explore the impact of using raw values versus log transformed values. We will define a plotting function to visualize the cutoff threshold using 5 MAD's on a histogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_histograms_with_MAD(adata, obs1, obs2, madunits, bins=100):\n",
    "    \"\"\"\n",
    "    Plots two histograms side by side with their means & 5 MAD's labeled \n",
    "\n",
    "    Args:\n",
    "        adata (AnnData): The dataset containing the variables to plot.\n",
    "        obs1 (str): The name of the first variable to plot.\n",
    "        obs2 (str): The name of the second variable to plot.\n",
    "        bins (int): Number of bins to use in the histograms. Default is 100.\n",
    "        mad_units (int): Number of MAD units for outlier detection.\n",
    "\n",
    "    Returns:\n",
    "        None: Displays the plots.\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare subplots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "\n",
    "    for ax, obs in zip(axes, [obs1, obs2]):\n",
    "        data = adata.obs[obs]\n",
    "        median_val = np.median(data)\n",
    "\n",
    "        # Apply \"is_outlier\" function\n",
    "        outliers = is_outlier(adata, obs, madunits)\n",
    "\n",
    "        # Plot histograms\n",
    "        sns.histplot(data, bins=bins, ax=ax, kde=False)\n",
    "        upper_threshold = np.median(data) + madunits * median_abs_deviation(data)\n",
    "        ax.axvline(upper_threshold, color=\"red\", linestyle=\"--\", label=f\"{madunits} MADs: {upper_threshold:.2f}\")\n",
    "\n",
    "        # Median line\n",
    "        ax.axvline(median_val, color=\"orange\", linestyle=\"-\", label=f\"Median: {median_val:.2f}\")\n",
    "\n",
    "        # Titles and labels\n",
    "        ax.set_title(f\"Distribution of {obs}\")\n",
    "        ax.set_xlabel(obs)\n",
    "        ax.set_ylabel(\"Frequency\")\n",
    "        ax.legend()\n",
    "\n",
    "    # Adjust layout and show\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot total transcript counts by log transformed total transcripts\n",
    "plot_histograms_with_MAD(adata, \"total_counts\", \"log1p_total_counts\", madunits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot unique gene counts by log transformed values of the same\n",
    "plot_histograms_with_MAD(adata, \"n_genes_by_counts\", \"log1p_n_genes_by_counts\", madunits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that using raw counts for outlier detection will result in a high number of cells being eliminated. Additionally, the use of raw counts does not properly account for the skewness of RNA data, while log transformed values will likely allow for a better representation of the overall data with a more representative median that is less impacted by strong outlier cells. \n",
    "\n",
    "Additionally, we can apply the `is_outlier` function to both log transformed and log transformed values to get a count of the number of cells that would be identified as outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection using log transformed values\n",
    "log_outliers = (\n",
    "    is_outlier(adata, \"log1p_total_counts\", 5)\n",
    "    | is_outlier(adata, \"log1p_n_genes_by_counts\", 5)\n",
    ")\n",
    "\n",
    "# using count values\n",
    "raw_outliers = (\n",
    "    is_outlier(adata, \"total_counts\", 5)\n",
    "    | is_outlier(adata, \"n_genes_by_counts\", 5)\n",
    ")\n",
    "\n",
    "print(f\"Using raw values results in: {raw_outliers.sum()} outliers.\\nWhile log transformed values result in: {log_outliers.sum()} outliers. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will move forward with log transformed values to keep in line with \"permissive filtering\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot unique gene counts by log transformed values of the same\n",
    "plot_histograms_with_MAD(adata, \"pct_counts_in_top_20_genes\", \"pct_counts_mt\", madunits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using count values\n",
    "top20_outliers = (\n",
    "    is_outlier(adata, \"pct_counts_in_top_20_genes\", 5)\n",
    ")\n",
    "\n",
    "mt_outliers = (\n",
    "    is_outlier(adata, \"pct_counts_mt\", 5)\n",
    ")\n",
    "\n",
    "print(f\"Top 20 genes metric results in: {top20_outliers.sum()} outliers\")\n",
    "\n",
    "print(f\"Mitochondrial gene precentage metric results in: {mt_outliers.sum()} outliers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pct_counts_in_top_20_genes` is describes as percentage of total counts contributed by the top 20 most highly expressed genes in a given cell. This metric results in a large number of outliers being detected. These could be true positive or true negative detections. \n",
    "\n",
    "In the case that the outliers are correctly identified, our data could benefit from removing those cells as they are heavily dominated by a small subset of genes. \n",
    "\n",
    "Alternitevly, we could erroniously eliminate real biologically relevant cells that naturally express a small subset of genes (such as plasma cells, who'se major role is antibody production)\n",
    "\n",
    "We will leave this consideration for a second round of QC, and allow these 133 cells into the analysis for now. \n",
    "\n",
    "The result is even more significant for mitochondrial gene presentage as a qc metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection usuing log transformed values\n",
    "adata.obs[\"outlier\"] = (\n",
    "    is_outlier(adata, \"log1p_total_counts\", 5)\n",
    "    | is_outlier(adata, \"log1p_n_genes_by_counts\", 5)\n",
    ")\n",
    "\n",
    "adata.obs.outlier.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast boolean value to category for plotting\n",
    "adata.obs[\"cat_outlier\"] = adata.obs[\"outlier\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show outliers on violin plot\n",
    "sc.pl.violin(\n",
    "    adata,\n",
    "    keys=[\"total_counts\", \"n_genes_by_counts\"],\n",
    "    size=3,\n",
    "    groupby=\"cat_outlier\",\n",
    "    multi_panel=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.scatter(adata, \"log1p_total_counts\", \"log1p_n_genes_by_counts\", size=50, color=\"cat_outlier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gene based QC\n",
    "In addition to QC metrics applied to filter out uninformative cells, we want to remove genes that are not expressed in enough cells to be useful for analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count genes with no expression in any cells\n",
    "print(\"Zero-variance genes pre-filtering:\", np.sum(adata.X.var(axis=0) == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep genes expressed in at least one cell\n",
    "sc.pp.filter_genes(adata, min_cells=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check filerting results\n",
    "print(\"Zero-variance genes post-filtering:\", np.sum(adata.X.var(axis=0) == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Data\n",
    "\n",
    "Keeping in mind that we will likely return to this choice of QC application, we can move forward with out chosen threshold and filter out data. \n",
    "\n",
    "Apply ambient RNA detection methods\n",
    "- SoupX [Young and Behjati, 2020](https://doi.org/10.1093/gigascience/giaa151) (required raw feature data)\n",
    "- DecontX [Yang et al., 2020](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-1950-6) \n",
    "\n",
    "Apply doubled detection method\n",
    "- scDblFinder [Xi and Li, 2021](https://www.sciencedirect.com/science/article/pii/S2666166721004068?via%3Dihub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total number of cells: {adata.n_obs}\")\n",
    "adata = adata[(~adata.obs.outlier)].copy()\n",
    "\n",
    "print(f\"Number of cells after filtering of low quality cells: {adata.n_obs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization\n",
    "\n",
    "The process of RNA sequencing involves many steps that introduce bias into our counts data. \n",
    "\n",
    "- Technican variability: Two identical cells can have highly different counts for any given gene due to differences in processing, reverse transcription, amplificiation and sequencing steps. This results in two cells that for all intents and purposes are identical, appearing to have biologically relevant differences in gene signatures. The use of Unique Molecular Identifiers help reduce the technical noise produced during PCR, but cannot account for other steps of variability production.  \n",
    "\n",
    "- Gene size variability: Larger genes will have more sequencing targets than smaller genes and may appear to have higher expression because of that fact. \n",
    "\n",
    "- Mean-Variance: The ground truth of RNA amplification has long been considered to fall along a logrithmic distribution, specifically a log 2 transformation. The reality is in fact convoluded by various factors such as feedback loops, signaling pathways, environmental factors, selective inhibition, and transcriptional bursts. As such, log based normalization methods cannot perfectly account for over dispersian of RNA expression. A Poisson based model with a Gamma scaling facor has been discovered to better fit RNA expression varibility.\n",
    "\n",
    "- Downstream Statistics: Lastly, many downstream analysis methodologies require normalized data in order to apply statistical methods. These include but are not limited to Clustering and dimensionality reduction, differential gene expression and pathway analyses. (Some pipelines may require raw data in order to apply their own normalization methods)\n",
    "\n",
    "Various normalization methods can be applied to data and much like the quality control portion of our workflow, data normalization requires careful consideration of the question at hand as well as an idea of what downstream analyses will be used. \n",
    "\n",
    "For our case we will apply an analytic approximation of Pearson residuals. [Normalization and variance stabilization of single-cell RNA-seq data using regularized negative binomial regression](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1874-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix # Stores and operates on sparse matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! not sure why this is required, but something is happening one of the previous code cells that nessesitates rerunning this code. \n",
    "sc.pp.filter_genes(adata, min_cells=1)\n",
    "\n",
    "# Compute Pearsons residuals and add normalized sparse matrix as adata layer\n",
    "analytic_pearson = sc.experimental.pp.normalize_pearson_residuals(adata, inplace=False)\n",
    "adata.layers[\"pearson_residuals\"] = csr_matrix(analytic_pearson[\"X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms\n",
    "fig, ax = plt.subplots(1, 3, figsize=(18, 6))  \n",
    "\n",
    "# Raw Counts Histogram\n",
    "sns.histplot(adata.obs[\"total_counts\"], bins=100, kde=False, ax=ax[0])\n",
    "ax[0].set_title(\"Raw Counts\")\n",
    "\n",
    "# Log-Transformed Counts Histogram\n",
    "sns.histplot(adata.obs[\"log1p_total_counts\"], bins=100, kde=False, ax=ax[1])\n",
    "ax[1].set_title(\"Pseudo Log Transformed Counts\")\n",
    "\n",
    "# Pearson Residuals Histogram (convert sparse matrix to dense with .A1)\n",
    "sns.histplot(adata.layers[\"pearson_residuals\"].sum(1).A1, bins=100, kde=False, ax=ax[2]) \n",
    "ax[2].set_title(\"Pearson Residuals Transformed Counts\")\n",
    "\n",
    "# Display \n",
    "plt.tight_layout()  \n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "Much of RNA sequencing data is actually quite uninformative in nature. Many genes are comparably expressed between many cell types under homeostatic conditions, these housekeeping genes do not add value to a final analysis (although they can provide a lot of benefit for quality assesement). Additionally most RNA sequencing experiments are targetted at specific tissues or cell types, meaning that certain gene signatures provide little insight of value. In a perfect world where computational costs were not a consideration, it may be interested to use all 20-30,000 genes of a typical single cell experiment for downstream analysis, but in reality this is not feasable when a single sample can contain thousands of cells with many samples in an experiment. \n",
    "\n",
    "Therefor it is standard practice to subset our genes for the most variably expressed genes. Not simply for the genes that are highly expressed, as this could include housekeeping genes like Beta Acting and GAPDH, but genes that have a high degree of variablity between cell types. These genes are generally considered to be the informative signatures worth keeping for downstream analysis. \n",
    "\n",
    "Once again, various methods exist for applying this selection criteria. \n",
    "- For now, we will use Scanpy's `sc.pp.highly_variable_genes` with Seurat modification [Comprehensive Integration of Single-Cell Data](https://www.cell.com/cell/fulltext/S0092-8674(19)30559-8?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0092867419305598%3Fshowall%3Dtrue)\n",
    "- An alternate method we will try in the future uses deviance method to rank genes [Feature selection and dimension reduction for single-cell RNA-Seq based on a multinomial model](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1861-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check filerting results\n",
    "print(\"Zero-variance genes post-filtering:\", np.sum(adata.X.var(axis=0) == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check filerting results\n",
    "adata.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top 200 highly variable genes\n",
    "sc.pp.highly_variable_genes(adata, n_top_genes=2000, flavor='seurat_v3', span=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our gene information now includes a columns for a boolean indication of `highly_variable` and its `highly_variable_rank` with some statistics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot highly variable genes\n",
    "sc.pl.highly_variable_genes(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out non highly variable genes\n",
    "adata = adata[:,adata.var.highly_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot again\n",
    "sc.pl.highly_variable_genes(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction\n",
    "\n",
    "Once we have subset our genes to the most informative subsets, we are still left with more genes than the human mind can easily comprehend. Additionally high dimensional data does not always mean informative data, much of the information we have on hand could be a product of noise and various other artifacts. This is where unsupervised machine learning methods such as clustering and dimensionality reduction come into play. These methods take the 2000+/- genes in our data and without any labels to inform grouping (unsupervised) they apply various statistical methods to reduce the number of dimensions to a handful of informative dimensions. \n",
    "\n",
    "As always various methods exist and are continuesly refined. Some default apporaches include:\n",
    "- `Principle Component Analysis (PCA)`: Finds linear combinations of features that maximaize variance and groups them into sets of principle components.\n",
    "    - An old method but still widely used\n",
    "    - Excellent for reducing dimensinality for downstream workflows. \n",
    "    - Not great with visualization\n",
    "- `Stochastic Neighbor Embedding (tSNE)`: Uses pair wise similarties to reduce the dimensionaity of data\n",
    "    - Can be computationally expensive for large datasets\n",
    "- `Uniform Manifold Approximation and Projection (UMAP)`: Applies k-nearest neighbors approach to high dimensional data. \n",
    "    - Highly stable and does an excelent job at seperating cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap normalized values for raw counts\n",
    "adata.X = adata.layers[\"pearson_residuals\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA \n",
    "sc.pp.pca(adata, svd_solver=\"arpack\", mask_var=\"highly_variable\")\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that we have included additional variables into our Anndata object after running PCA. Specifically we have the default addition of 50 Priniciple Components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.uns[\"pca\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a variance ratio plot (aka: elbow plot) to visualize the impact of each PC on the variance of the data. The Y-Axis denotes the amount of variance that the given X value describes. This plot can be used to identify the number of PC's that provide meaningful insight into the data, this is done by identifying the elbox joint in the plot (the point in the plot where additional PC's do not account for much more variability in the data). In the spirit of permissive filtering, it is accepted practice to slightly overshoot the elbow point. In the plot below, i might select anywhere from 10-12 PC's to move forward with the analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot elbow curve\n",
    "sc.pl.pca_variance_ratio(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally we can inspect the PCA loadings to determine the genes and their linear combinations that are influencing our first few PC's. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.pca_loadings(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we can plot the first two PC's (or any others) to visualize how well the cells are groups. (this result is generally not very informative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "sc.pl.pca_scatter(adata, color=\"total_counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply tSNE\n",
    "sc.tl.tsne(adata, use_rep=\"X_pca\")\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize tSNE\n",
    "sc.pl.tsne(adata, color=\"total_counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP\n",
    "sc.pp.neighbors(adata, n_pcs=12)\n",
    "sc.tl.umap(adata)\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "sc.pl.umap(adata, color=\"total_counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect quality control \n",
    "sc.pl.umap(\n",
    "    adata,\n",
    "    color=[\"total_counts\", \"pct_counts_mt\", \"pct_counts_ribo\", \"pct_counts_hb\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell Clusters\n",
    "\n",
    "In order to computationally determine the cluster assignments, we utlize Leiden clustering. [From Louvain to Leiden: guaranteeing well-connected communities](https://www.nature.com/articles/s41598-019-41695-z). Leiden clustering uses K Nearest Neighbores (KNN) method to groups cells based on a predefined (but meaningless) resolution metric (default is 1.0, higher values product more clusters). This requires some refinement and can be further optimized by increasing the resolution of a subcluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call Leiden algoritm with various resolutions that are saved into out Anndata object\n",
    "sc.tl.leiden(adata, key_added=\"leiden_res0_25\", resolution=0.25)\n",
    "sc.tl.leiden(adata, key_added=\"leiden_res0_5\", resolution=0.5)\n",
    "sc.tl.leiden(adata, key_added=\"leiden_res1\", resolution=1.0)\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize outputs\n",
    "sc.pl.umap(\n",
    "    adata,\n",
    "    color=[\"leiden_res0_25\", \"leiden_res0_5\", \"leiden_res1\"],\n",
    "    legend_loc=\"on data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "Now that we have developed a structure for importing, cleaning, normalizing and clustering a single patient sample, we will draft a pipeline to perform the same workflow on the ramaining samples in the original dataset. In the end we want to obtain a single Anndata object that contains all the cells from the 26 patient sample. This tast is expected to be computationally expensive and may require cloud computing services or high powered CPU's and/or GPU's in our personal computers. \n",
    "\n",
    "Once we have a singular Anndata object, we will confirm that the integration of the patient samples looks good, save out Anndata object and move foreward to idenitifying and annotating our cell types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Total size of the AnnData object\n",
    "print(f\"Total memory of AnnData object: {sys.getsizeof(adata) / 1e6} MB\")\n",
    "\n",
    "# Size of main components\n",
    "print(f\"Memory for .X (expression matrix): {sys.getsizeof(adata.X) / 1e6} MB\")\n",
    "print(f\"Memory for .obs (cell metadata): {sys.getsizeof(adata.obs) / 1e6} MB\")\n",
    "print(f\"Memory for .var (gene metadata): {sys.getsizeof(adata.var) / 1e6} MB\")\n",
    "print(f\"Memory for .uns (unstructured data): {sys.getsizeof(adata.uns) / 1e6} MB\")\n",
    "print(f\"Memory for .layers (custom layers): {sys.getsizeof(adata.layers) / 1e6} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.X = csr_matrix(adata.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total size of the AnnData object\n",
    "print(f\"Total memory of AnnData object: {sys.getsizeof(adata) / 1e6} MB\")\n",
    "\n",
    "# Size of main components\n",
    "print(f\"Memory for .X (expression matrix): {sys.getsizeof(adata.X) / 1e6} MB\")\n",
    "print(f\"Memory for .obs (cell metadata): {sys.getsizeof(adata.obs) / 1e6} MB\")\n",
    "print(f\"Memory for .var (gene metadata): {sys.getsizeof(adata.var) / 1e6} MB\")\n",
    "print(f\"Memory for .uns (unstructured data): {sys.getsizeof(adata.uns) / 1e6} MB\")\n",
    "print(f\"Memory for .layers (custom layers): {sys.getsizeof(adata.layers) / 1e6} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM used: 11.334467584 GB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "print(\"RAM used:\", psutil.virtual_memory().used / 1e9, \"GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # Numerical computing library\n",
    "import pandas as pd  # Data manipulation and analysis\n",
    "import matplotlib.pyplot as plt  # Plotting and visualization\n",
    "import seaborn as sns  # Statistical data visualization\n",
    "import scanpy as sc  # Single-cell data analysis\n",
    "import scvi  # Single-cell variational inference for modeling\n",
    "from scipy.stats import median_abs_deviation  # Robust statistic for dispersion\n",
    "import os  # Operating system interface\n",
    "from scipy.sparse import csr_matrix \n",
    "\n",
    "# Create MAD function\n",
    "def is_outlier(adata, qcmetric: str, madunits: int):\n",
    "    \"\"\"\n",
    "    Identified outlier points using the Mean Absolute Deviation function from scipy\n",
    "\n",
    "    Args:\n",
    "        adata (_type_): Anndata object with RNA data\n",
    "        qcmetric (str): QC metric to use for outlier detection\n",
    "        madunits (int): Value of MAD units to use for the QC metric\n",
    "\n",
    "    Returns:\n",
    "        _type_: Boolean value identifying outliers\n",
    "    \"\"\"\n",
    "    M = adata.obs[qcmetric]\n",
    "    outlier = (M < np.median(M) - madunits * median_abs_deviation(M)) | (M > np.median(M) + madunits * median_abs_deviation(M))\n",
    "    return outlier\n",
    "\n",
    "\n",
    "def Process_and_integrate(csv_dir):\n",
    "    import anndata\n",
    "    adata_list = []  # Initialize a list to store AnnData objects\n",
    "    \n",
    "    \n",
    "    for file in os.listdir(csv_dir):\n",
    "        file_path = os.path.join(csv_dir, file)\n",
    "        if file.endswith('.csv'): \n",
    "            adata = sc.read_csv(file_path).T\n",
    "            sample_name = file.split(\"_\")[1]  \n",
    "            adata.obs[\"Sample\"] = sample_name\n",
    "            print(f\"{sample_name} has {adata.X.shape[0]} cells and {adata.X.shape[1]} transcripts\")\n",
    "\n",
    "            # Annotate mitochondrial, ribosomal, and hemoglobin genes\n",
    "            adata.var[\"mt\"] = adata.var_names.str.startswith(\"MT-\")\n",
    "            adata.var[\"ribo\"] = adata.var_names.str.startswith((\"RPS\", \"RPL\"))\n",
    "            adata.var[\"hb\"] = adata.var_names.str.contains((\"^HB[^(P)]\"))\n",
    "\n",
    "            # Calculate QC metrics\n",
    "            sc.pp.calculate_qc_metrics(adata, qc_vars=[\"mt\", \"ribo\", \"hb\"], inplace=True, percent_top=[20], log1p=True)\n",
    "\n",
    "            # Remove outliers\n",
    "            adata.obs[\"outlier\"] = (\n",
    "                    is_outlier(adata, \"log1p_total_counts\", 5)\n",
    "                    | is_outlier(adata, \"log1p_n_genes_by_counts\", 5)\n",
    "            )\n",
    "            print(adata.obs.outlier.value_counts())\n",
    "            adata = adata[(~adata.obs.outlier)].copy()\n",
    "\n",
    "            # Filter zero-variance genes\n",
    "            sc.pp.filter_genes(adata, min_cells=1)\n",
    "            sc.pp.filter_genes(adata, min_counts=1)\n",
    "\n",
    "            # Normalize with Pearson residuals\n",
    "            analytic_pearson = sc.experimental.pp.normalize_pearson_residuals(adata, inplace=False)\n",
    "            adata.layers[\"pearson_residuals\"] = csr_matrix(analytic_pearson[\"X\"])\n",
    "\n",
    "            # Filter zero-variance genes\n",
    "            sc.pp.filter_genes(adata, min_cells=1)\n",
    "            sc.pp.filter_genes(adata, min_counts=1)\n",
    "\n",
    "            # Identify highly variable genes\n",
    "            sc.pp.highly_variable_genes(adata, n_top_genes=2000, flavor='seurat_v3', span=1.0)\n",
    "\n",
    "            # Convert to sparse matrix for memory \n",
    "            adata.X = csr_matrix(adata.X)\n",
    "\n",
    "            print(f\"{sample_name} has been processed\\n\")\n",
    "            adata_list.append(adata)  # Add processed AnnData object to list\n",
    "    \n",
    "    # Concatenate objects\n",
    "    combined_adata = anndata.concat(\n",
    "        adata_list,\n",
    "        merge='same', \n",
    "        label='Sample',\n",
    "        keys=[ad.obs['Sample'][0] for ad in adata_list]\n",
    "    )\n",
    "    return combined_adata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C51ctr has 6099 cells and 34546 transcripts\n",
      "outlier\n",
      "False    6094\n",
      "True        5\n",
      "Name: count, dtype: int64\n",
      "C51ctr has been processed\n",
      "\n",
      "C52ctr has 4513 cells and 34546 transcripts\n",
      "outlier\n",
      "False    4513\n",
      "Name: count, dtype: int64\n",
      "C52ctr has been processed\n",
      "\n",
      "C53ctr has 7120 cells and 34546 transcripts\n",
      "outlier\n",
      "False    7113\n",
      "True        7\n",
      "Name: count, dtype: int64\n",
      "C53ctr has been processed\n",
      "\n",
      "C54ctr has 4382 cells and 34546 transcripts\n",
      "outlier\n",
      "False    4378\n",
      "True        4\n",
      "Name: count, dtype: int64\n",
      "C54ctr has been processed\n",
      "\n",
      "C55ctr has 5685 cells and 34546 transcripts\n",
      "outlier\n",
      "False    5673\n",
      "True       12\n",
      "Name: count, dtype: int64\n",
      "C55ctr has been processed\n",
      "\n",
      "C56ctr has 4090 cells and 34546 transcripts\n",
      "outlier\n",
      "False    4081\n",
      "True        9\n",
      "Name: count, dtype: int64\n",
      "C56ctr has been processed\n",
      "\n",
      "C57ctr has 4789 cells and 34546 transcripts\n",
      "outlier\n",
      "False    4776\n",
      "True       13\n",
      "Name: count, dtype: int64\n",
      "C57ctr has been processed\n",
      "\n",
      "L01cov has 3060 cells and 34546 transcripts\n",
      "outlier\n",
      "False    3053\n",
      "True        7\n",
      "Name: count, dtype: int64\n",
      "L01cov has been processed\n",
      "\n",
      "L03cov has 5060 cells and 34546 transcripts\n",
      "outlier\n",
      "False    5060\n",
      "Name: count, dtype: int64\n",
      "L03cov has been processed\n",
      "\n",
      "L04cov has 3630 cells and 34546 transcripts\n",
      "outlier\n",
      "False    3619\n",
      "True       11\n",
      "Name: count, dtype: int64\n",
      "L04cov has been processed\n",
      "\n",
      "L04covaddon has 4574 cells and 34546 transcripts\n",
      "outlier\n",
      "False    4572\n",
      "True        2\n",
      "Name: count, dtype: int64\n",
      "L04covaddon has been processed\n",
      "\n",
      "L05cov has 3052 cells and 34546 transcripts\n",
      "outlier\n",
      "False    3052\n",
      "Name: count, dtype: int64\n",
      "L05cov has been processed\n",
      "\n",
      "L06cov has 7582 cells and 34546 transcripts\n",
      "outlier\n",
      "False    7571\n",
      "True       11\n",
      "Name: count, dtype: int64\n",
      "L06cov has been processed\n",
      "\n",
      "L07cov has 5074 cells and 34546 transcripts\n",
      "outlier\n",
      "False    5070\n",
      "True        4\n",
      "Name: count, dtype: int64\n",
      "L07cov has been processed\n",
      "\n",
      "L08cov has 4149 cells and 34546 transcripts\n",
      "outlier\n",
      "False    4149\n",
      "Name: count, dtype: int64\n",
      "L08cov has been processed\n",
      "\n",
      "L09cov has 3605 cells and 34546 transcripts\n",
      "outlier\n",
      "False    3592\n",
      "True       13\n",
      "Name: count, dtype: int64\n",
      "L09cov has been processed\n",
      "\n",
      "L10cov has 1550 cells and 34546 transcripts\n",
      "outlier\n",
      "False    1547\n",
      "True        3\n",
      "Name: count, dtype: int64\n",
      "L10cov has been processed\n",
      "\n",
      "L11cov has 3296 cells and 34546 transcripts\n",
      "outlier\n",
      "False    3295\n",
      "True        1\n",
      "Name: count, dtype: int64\n",
      "L11cov has been processed\n",
      "\n",
      "L12cov has 3876 cells and 34546 transcripts\n",
      "outlier\n",
      "False    3863\n",
      "True       13\n",
      "Name: count, dtype: int64\n",
      "L12cov has been processed\n",
      "\n",
      "L13cov has 4862 cells and 34546 transcripts\n",
      "outlier\n",
      "False    4860\n",
      "True        2\n",
      "Name: count, dtype: int64\n",
      "L13cov has been processed\n",
      "\n",
      "L15cov has 4056 cells and 34546 transcripts\n",
      "outlier\n",
      "False    4056\n",
      "Name: count, dtype: int64\n",
      "L15cov has been processed\n",
      "\n",
      "L16cov has 1822 cells and 34546 transcripts\n",
      "outlier\n",
      "False    1821\n",
      "True        1\n",
      "Name: count, dtype: int64\n",
      "L16cov has been processed\n",
      "\n",
      "L17cov has 4651 cells and 34546 transcripts\n",
      "outlier\n",
      "False    4648\n",
      "True        3\n",
      "Name: count, dtype: int64\n",
      "L17cov has been processed\n",
      "\n",
      "L18cov has 2816 cells and 34546 transcripts\n",
      "outlier\n",
      "False    2787\n",
      "True       29\n",
      "Name: count, dtype: int64\n",
      "L18cov has been processed\n",
      "\n",
      "L19cov has 2509 cells and 34546 transcripts\n",
      "outlier\n",
      "False    2509\n",
      "Name: count, dtype: int64\n",
      "L19cov has been processed\n",
      "\n",
      "L21cov has 3425 cells and 34546 transcripts\n",
      "outlier\n",
      "False    3413\n",
      "True       12\n",
      "Name: count, dtype: int64\n",
      "L21cov has been processed\n",
      "\n",
      "L22cov has 6987 cells and 34546 transcripts\n",
      "outlier\n",
      "False    6980\n",
      "True        7\n",
      "Name: count, dtype: int64\n",
      "L22cov has been processed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_992\\2800517869.py:84: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  keys=[ad.obs['Sample'][0] for ad in adata_list]\n"
     ]
    }
   ],
   "source": [
    "combined_adata = Process_and_integrate(\"data/GSE171524_RAW/csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs ร n_vars = 116145 ร 17230\n",
       "    obs: 'Sample', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_20_genes', 'total_counts_mt', 'log1p_total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'log1p_total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'log1p_total_counts_hb', 'pct_counts_hb', 'outlier'\n",
       "    var: 'mt', 'ribo', 'hb'\n",
       "    layers: 'pearson_residuals'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_adata.write(\"COVID19_QCd_Pooled_Samples.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory of AnnData object: 16878.553729 MB\n",
      "Memory for .X (expression matrix): 4.8e-05 MB\n",
      "Memory for .obs (cell metadata): 20.445265 MB\n",
      "Memory for .var (gene metadata): 1.532304 MB\n",
      "Memory for .uns (unstructured data): 0.000128 MB\n",
      "Memory for .layers (custom layers): 4.8e-05 MB\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# Total size of the AnnData object\n",
    "print(f\"Total memory of AnnData object: {sys.getsizeof(combined_adata) / 1e6} MB\")\n",
    "\n",
    "# Size of main components\n",
    "print(f\"Memory for .X (expression matrix): {sys.getsizeof(combined_adata.X) / 1e6} MB\")\n",
    "print(f\"Memory for .obs (cell metadata): {sys.getsizeof(combined_adata.obs) / 1e6} MB\")\n",
    "print(f\"Memory for .var (gene metadata): {sys.getsizeof(combined_adata.var) / 1e6} MB\")\n",
    "print(f\"Memory for .uns (unstructured data): {sys.getsizeof(combined_adata.uns) / 1e6} MB\")\n",
    "print(f\"Memory for .layers (custom layers): {sys.getsizeof(combined_adata.layers) / 1e6} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in combined_adata.uns.items():\n",
    "    print(f\"{key}: {type(value)}, {sys.getsizeof(value) / 1024**2:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotations\n",
    "\n",
    "Finally we arrive at the argueble most difficult portion of our analysis. Interpreting the data into biologically relevant cell types. \n",
    "\n",
    "Like essentially every step along the way, this is a highly itterative step that requires domain knowledge or a cleaver application of key resources. \n",
    "\n",
    "Much like sanding a 3D printed object or a wood carving, its generally a good idea to start with coarse identification of cell types and transition towards more fine grained annotations such as activation states and subpopulations. An ideal starting place is to determine commonly known cell types such as B-Cells and T-Cells, which are normally well defined in clustering outputs and have unique gene signatures that can easily differentiate them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discoveries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Session Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import session_info\n",
    "session_info.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Session Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace spaces in notebook title with underscores\n",
    "filename = Notebook_title.replace(\" \", \"_\") + \"_requirements.txt\"\n",
    "\n",
    "# Run the pip freeze command and save the output txt file\n",
    "!pip freeze > $filename"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
